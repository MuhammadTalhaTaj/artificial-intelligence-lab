{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P54sbhNR5NST"
      },
      "outputs": [],
      "source": [
        "#1\n",
        "class Problem(object):\n",
        "\n",
        "    \n",
        "\n",
        "    def __init__(self, initial, goal=None):\n",
        "       \n",
        "        self.initial = initial\n",
        "        self.goal = goal\n",
        "\n",
        "    def actions(self, state):\n",
        "        \n",
        "        raise NotImplementedError\n",
        "\n",
        "    def result(self, state, action):\n",
        "      \n",
        "        raise NotImplementedError\n",
        "\n",
        "    def goal_test(self, state):\n",
        "       \n",
        "        if isinstance(self.goal, list):\n",
        "            return is_in(state, self.goal)\n",
        "        else:\n",
        "            return state == self.goal\n",
        "\n",
        "    def path_cost(self, c, state1, action, state2):\n",
        "        \n",
        "        return c + 1\n",
        "\n",
        "    def value(self, state):\n",
        "        \n",
        "        raise NotImplementedError\n",
        "\n",
        "class Node:\n",
        "\n",
        "\n",
        "\n",
        "    def __init__(self, state, parent=None, action=None, path_cost=0):\n",
        "        \"\"\"Create a search tree Node, derived from a parent by an action.\"\"\"\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.action = action\n",
        "        self.path_cost = path_cost\n",
        "        self.depth = 0\n",
        "        if parent:\n",
        "            self.depth = parent.depth + 1\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"{}>\".format(self.state)\n",
        "\n",
        "    def __lt__(self, node):\n",
        "        return self.state < node.state\n",
        "\n",
        "    def expand(self, problem):\n",
        "        \"\"\"List the nodes reachable in one step from this node.\"\"\"\n",
        "        return [self.child_node(problem, action)\n",
        "                for action in problem.actions(self.state)]\n",
        "\n",
        "    def child_node(self, problem, action):\n",
        "        \"\"\"[Figure 3.10]\"\"\"\n",
        "        next_state = problem.result(self.state, action)\n",
        "        next_node = Node(next_state, self, action,\n",
        "                    problem.path_cost(self.path_cost, self.state,\n",
        "                                      action, next_state))\n",
        "        return next_node\n",
        "    \n",
        "    def solution(self):\n",
        "        \"\"\"Return the sequence of actions to go from the root to this node.\"\"\"\n",
        "        return [node.action for node in self.path()[1:]]\n",
        "\n",
        "    def path(self):\n",
        "        \"\"\"Return a list of nodes forming the path from the root to this node.\"\"\"\n",
        "        node, path_back = self, []\n",
        "        while node:\n",
        "            path_back.append(node)\n",
        "            node = node.parent\n",
        "        return list(reversed(path_back))\n",
        "\n",
        "    # We want for a queue of nodes in breadth_first_graph_search or\n",
        "    # astar_search to have no duplicated states, so we treat nodes\n",
        "    # with the same state as equal. [Problem: this may not be what you\n",
        "    # want in other contexts.]\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return isinstance(other, Node) and self.state == other.state\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.state)\n",
        "\n",
        "\n",
        "romania_map = (dict(\n",
        "    Arad=dict(Zerind=75, Sibiu=140, Timisoara=118),\n",
        "    Bucharest=dict(Urziceni=85, Pitesti=101, Giurgiu=90, Fagaras=211),\n",
        "    Craiova=dict(Drobeta=120, Rimnicu=146, Pitesti=138),\n",
        "    Drobeta=dict(Mehadia=75),\n",
        "    Eforie=dict(Hirsova=86),\n",
        "    Fagaras=dict(Sibiu=99),\n",
        "    Hirsova=dict(Urziceni=98),\n",
        "    Iasi=dict(Vaslui=92, Neamt=87),\n",
        "    Lugoj=dict(Timisoara=111, Mehadia=70),\n",
        "    Oradea=dict(Zerind=71, Sibiu=151),\n",
        "    Pitesti=dict(Rimnicu=97),\n",
        "    Rimnicu=dict(Sibiu=80),\n",
        "    Urziceni=dict(Vaslui=142)))\n",
        "\n",
        "romania_map = dict(\n",
        "    Arad=(91, 492), Bucharest=(400, 327), Craiova=(253, 288),\n",
        "    Drobeta=(165, 299), Eforie=(562, 293), Fagaras=(305, 449),\n",
        "    Giurgiu=(375, 270), Hirsova=(534, 350), Iasi=(473, 506),\n",
        "    Lugoj=(165, 379), Mehadia=(168, 339), Neamt=(406, 537),\n",
        "    Oradea=(131, 571), Pitesti=(320, 368), Rimnicu=(233, 410),\n",
        "    Sibiu=(207, 457), Timisoara=(94, 410), Urziceni=(456, 350),\n",
        "    Vaslui=(509, 444), Zerind=(108, 531))\n",
        "\n",
        "\n",
        "def depth_limited_search_for_vis(problem):\n",
        "    \"\"\"Search the deepest nodes in the search tree first.\"\"\"\n",
        "    iterations, all_node_colors, node = depth_limited_search_graph(problem)\n",
        "    return(iterations, all_node_colors, node)\n",
        "\n",
        "def iterative_deepening_search_for_vis(problem):\n",
        "    for depth in range(sys.maxsize):\n",
        "        iterations, all_node_colors, node=depth_limited_search_for_vis(problem)\n",
        "        if iterations:\n",
        "            return (iterations, all_node_colors, node)\n",
        "\n",
        "all_node_colors = []\n",
        "romania_problem = GraphProblem('Arad', 'Bucharest', romania_map)\n",
        "display_visual(romania_graph_data, user_input=False, \n",
        "               algorithm=iterative_deepening_search_for_vis, \n",
        "               problem=romania_problem)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "\n",
        "class Trie:\n",
        "    # Constructor\n",
        "    def __init__(self):\n",
        "        self.character = {}\n",
        "        self.isLeaf = False  \n",
        " \n",
        " \n",
        "def insert(root, s):\n",
        "    curr = root\n",
        " \n",
        "    for ch in s:\n",
        "        curr = curr.character.setdefault(ch, Trie())\n",
        " \n",
        "    curr.isLeaf = True\n",
        " \n",
        " \n",
        "\n",
        "row = [-1, -1, -1, 0, 1, 0, 1, 1]\n",
        "col = [-1, 1, 0, -1, -1, 1, 0, 1]\n",
        " \n",
        "\n",
        "def isSafe(x, y, processed, board, ch):\n",
        "    return (0 <= x < len(processed)) and (0 <= y < len(processed[0])) and \\\n",
        "           not processed[x][y] and (board[x][y] == ch)\n",
        " \n",
        " \n",
        "def searchBoggle(root, board, i, j, processed, path, result):\n",
        "    if root.isLeaf:\n",
        "        # update result with the current word\n",
        "        result.add(path)\n",
        " \n",
        "    # mark the current cell as processed\n",
        "    processed[i][j] = True\n",
        " \n",
        "    # traverse all children of the current Trie node\n",
        "    for key, value in root.character.items():\n",
        " \n",
        "        # check for all eight possible movements from the current cell\n",
        "        for k in range(len(row)):\n",
        " \n",
        "            # skip if a cell is invalid, or it is already processed\n",
        "            # or doesn't lead to any path in the Trie\n",
        "            if isSafe(i + row[k], j + col[k], processed, board, key):\n",
        "                searchBoggle(value, board, i + row[k], j + col[k],\n",
        "                             processed, path + key, result)\n",
        " \n",
        "    # backtrack: mark the current cell as unprocessed\n",
        "    processed[i][j] = False\n",
        " \n",
        " \n",
        "# Function to search for a given set of words in a boggle\n",
        "def searchInBoggle(board, words):\n",
        "    # construct a set for storing the result\n",
        "    result = set()\n",
        " \n",
        "    # base case\n",
        "    if not board or not len(board):\n",
        "        return\n",
        " \n",
        "    # insert all words into a trie\n",
        "    root = Trie()\n",
        "    for word in words:\n",
        "        insert(root, word)\n",
        " \n",
        "    # `M Ã— N` board\n",
        "    (M, N) = (len(board), len(board[0]))\n",
        " \n",
        "    # construct a matrix to store whether a cell is processed or not\n",
        "    processed = [[False for x in range(N)] for y in range(M)]\n",
        " \n",
        "    # consider each character in the matrix\n",
        "    for i in range(M):\n",
        "        for j in range(N):\n",
        "            ch = board[i][j]  # current character\n",
        " \n",
        "            # proceed only if the current character is a child of the Trie root node\n",
        "            if ch in root.character:\n",
        "                searchBoggle(root.character[ch], board, i, j, processed, ch, result)\n",
        " \n",
        "    # return the result set\n",
        "    return result\n",
        " \n",
        " \n",
        "if __name__ == '__main__':\n",
        "    board = [\n",
        "        ['M', 'S', 'E', 'F'],\n",
        "        ['R', 'A', 'T', 'D'],\n",
        "        ['L', 'O', 'N', 'E'],\n",
        "        ['K', 'A', 'F', 'B']\n",
        "    ]\n",
        " \n",
        "    words = ['START', 'NOTE', 'SAND', 'STONED']\n",
        "    searchInBoggle(board, words)\n",
        " \n",
        "    validWords = searchInBoggle(board, words)\n",
        "    print(validWords)"
      ],
      "metadata": {
        "id": "CCfBjo8t5PRK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}